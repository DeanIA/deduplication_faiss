{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Deduplication Workflow\n",
    "\n",
    "This notebook demonstrates the complete deduplication workflow using functions from `deduplicate_utils.py`.\n",
    "\n",
    "## Overview\n",
    "The workflow consists of three main steps:\n",
    "1. **Build ID Lookup**: Create a mapping from FAISS IDs to metadata\n",
    "2. **Collect Groups**: Use FAISS range search to find duplicate clusters\n",
    "3. **Write Results**: Export duplicate pairs to JSONL format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import json\n",
    "from pathlib import Path\n",
    "from deduplicate_utils import (\n",
    "    build_id_lookup,\n",
    "    collect_groups,\n",
    "    write_dedup_jsonl,\n",
    "    update_duplicate_flags\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set paths and parameters for deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "DATABASE_PATH = Path(\"descriptions.jsonl\")  # Your database file\n",
    "VIDEO_INDEX_PATH = Path(\"video_embeddings.index\")  # FAISS index for videos\n",
    "IMAGE_INDEX_PATH = Path(\"image_embeddings.index\")  # FAISS index for images\n",
    "VIDEO_EMBEDDINGS_PATH = Path(\"video_embeddings.npy\")  # Video embeddings\n",
    "IMAGE_EMBEDDINGS_PATH = Path(\"image_embeddings.npy\")  # Image embeddings\n",
    "\n",
    "# Deduplication mode\n",
    "MODE = \"duplicate\"  # Options: \"duplicate\" (strict) or \"similar\" (looser)\n",
    "\n",
    "# Set radius based on mode\n",
    "if MODE == \"duplicate\":\n",
    "    RADIUS = 0.9999  # Strict, exact duplicates\n",
    "elif MODE == \"similar\":\n",
    "    RADIUS = 0.99    # Looser, near-similar matches\n",
    "else:\n",
    "    raise ValueError(\"MODE must be 'duplicate' or 'similar'\")\n",
    "\n",
    "print(f\"Mode: {MODE}\")\n",
    "print(f\"Radius: {RADIUS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Database and Build ID Lookup\n",
    "\n",
    "Load the database and create a mapping from FAISS IDs to metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load database from JSONL\n",
    "database = []\n",
    "with open(DATABASE_PATH, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            database.append(json.loads(line))\n",
    "\n",
    "print(f\"Loaded {len(database)} entries from database\")\n",
    "\n",
    "# Build lookup table\n",
    "lookup = build_id_lookup(database)\n",
    "print(f\"Built lookup table with {len(lookup)} FAISS IDs\")\n",
    "\n",
    "# Display sample lookup entry\n",
    "if lookup:\n",
    "    sample_id = next(iter(lookup))\n",
    "    print(f\"\\nSample lookup entry (FAISS ID {sample_id}):\")\n",
    "    print(json.dumps(lookup[sample_id], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Video Deduplication\n",
    "\n",
    "Process video embeddings to find duplicate groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video embeddings and index\n",
    "video_embeddings = np.load(VIDEO_EMBEDDINGS_PATH)\n",
    "video_index = faiss.read_index(str(VIDEO_INDEX_PATH))\n",
    "\n",
    "print(f\"Loaded {len(video_embeddings)} video embeddings\")\n",
    "print(f\"FAISS index contains {video_index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate groups using FAISS range search\n",
    "video_groups = collect_groups(video_index, video_embeddings, radius=RADIUS)\n",
    "\n",
    "print(f\"Found {len(video_groups)} duplicate video groups\")\n",
    "\n",
    "# Show statistics about group sizes\n",
    "if video_groups:\n",
    "    group_sizes = [len(g) for g in video_groups]\n",
    "    print(f\"\\nGroup size statistics:\")\n",
    "    print(f\"  Min: {min(group_sizes)}\")\n",
    "    print(f\"  Max: {max(group_sizes)}\")\n",
    "    print(f\"  Average: {sum(group_sizes) / len(group_sizes):.2f}\")\n",
    "    \n",
    "    # Show largest group\n",
    "    largest_group = max(video_groups, key=len)\n",
    "    print(f\"\\nLargest group has {len(largest_group)} items:\")\n",
    "    print(f\"  FAISS IDs: {largest_group[:10]}{'...' if len(largest_group) > 10 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write video deduplication results to JSONL\n",
    "video_output_path = Path(f\"video_dedup_{MODE}.jsonl\")\n",
    "write_dedup_jsonl(video_groups, lookup, video_output_path)\n",
    "\n",
    "print(f\"Video deduplication results written to {video_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Image Deduplication\n",
    "\n",
    "Process image embeddings to find duplicate groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image embeddings and index\n",
    "image_embeddings = np.load(IMAGE_EMBEDDINGS_PATH)\n",
    "image_index = faiss.read_index(str(IMAGE_INDEX_PATH))\n",
    "\n",
    "print(f\"Loaded {len(image_embeddings)} image embeddings\")\n",
    "print(f\"FAISS index contains {image_index.ntotal} vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate groups using FAISS range search\n",
    "image_groups = collect_groups(image_index, image_embeddings, radius=RADIUS)\n",
    "\n",
    "print(f\"Found {len(image_groups)} duplicate image groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write image deduplication results to JSONL\n",
    "image_output_path = Path(f\"image_dedup_{MODE}.jsonl\")\n",
    "write_dedup_jsonl(image_groups, lookup, image_output_path)\n",
    "\n",
    "print(f\"Image deduplication results written to {image_output_path}\")\n",
    "\n",
    "# Count the number of duplicate pairs\n",
    "with open(image_output_path, 'r', encoding='utf-8') as f:\n",
    "    image_pairs = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "print(f\"Total image duplicate pairs: {len(image_pairs)}\")\n",
    "\n",
    "# Display sample pair\n",
    "if image_pairs:\n",
    "    print(\"\\nSample image duplicate pair:\")\n",
    "    print(json.dumps(image_pairs[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Summary Statistics\n",
    "\n",
    "Analyze the overall deduplication results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(f\"DEDUPLICATION SUMMARY (Mode: {MODE}, Radius: {RADIUS})\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nVideo Deduplication:\")\n",
    "print(f\"  Groups found: {len(video_groups)}\")\n",
    "print(f\"  File pairs: {len(video_pairs)}\")\n",
    "print(f\"  Output: {video_output_path}\")\n",
    "\n",
    "print(f\"\\nImage Deduplication:\")\n",
    "print(f\"  Groups found: {len(image_groups)}\")\n",
    "print(f\"  File pairs: {len(image_pairs)}\")\n",
    "print(f\"  Output: {image_output_path}\")\n",
    "\n",
    "print(f\"\\nTotal duplicate pairs: {len(video_pairs) + len(image_pairs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
